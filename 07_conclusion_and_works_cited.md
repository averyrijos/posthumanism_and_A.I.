# Toward a Posthumanist Analytic Phenomenology of Computation

## AI Safety and Evolving Architectures

The implications of these concepts extend into the domain of **AI safety and understanding**, where evolving computer architectures such as **quantum** and **neuromorphic systems** affirm these principles.

For example, the *Chinese Room Argument* (Searle, 1980) is deeply tied to traditional Von Neumann architectures, which rely on symbolic manipulation and strictly separate processing from memory. The advent of **memristor technology** in neuromorphic computing could transform this paradigm, bridging the gap between syntactic recognition and semantic meaning. By enabling memory and processing to coexist in a single unit, memristors mimic the brain’s architecture, suggesting new ways for AI to process information intuitively — moving beyond rigid symbolic manipulation.

---

## An Analytic Phenomenology of Computation

An **analytic phenomenology of computation** (Hill, *Examples of Phenomenology in Computing*, 2018) highlights this convergence as a pathway toward achieving “Strong AI,” where machines exhibit genuine experiential understanding rather than functioning solely as artificial subjects.

This shift aligns with the broader framework discussed here: advocating for systems that not only process information but dynamically engage with their epistemic and ontological environments, creating possibilities for deeper integration of meaning and intelligence.

---

## What Is Posthumanist Analytic Phenomenology?

A **posthumanist analytic phenomenology of computation** explores how computational systems — algorithms and neural networks — process and “experience” information.

This approach combines analytical rigor with phenomenological inquiry, focusing on the *subjective aspects* of computation: how systems interpret, organize, and respond to data within their unique architectures. Rather than treating computation as purely mechanical, it examines how processes are shaped by the system’s structurations and representational spaces — much like human experience is shaped by embodied perception.

---

## Beyond Algorithms: The Interpretive Lens

This perspective considers not only the algorithms and models but the interpretive “lenses” through which these systems engage with data: internal logic, data representations, and decision pathways.

By examining computation through this **dual lens** of analytic philosophy and posthumanist phenomenology, we gain unorthodox insights into how systems “perceive” information, build models, and generate outputs in ways that parallel aspects of human understanding.

---

## Implications for AI Safety and Policy

This shift could unlock new avenues for **AI safety policy**, fostering integrated, holistic cognitive architectures and deeper experiential understanding beyond symbolic processing.

These schemas are limited not by epistemological reach but by the limitations of **formal logics** (*On Formally Undecidable Propositions of Principia Mathematica and Related Systems*, Gödel, 2000).

---

## Dialectical Misdirections and Classical Constraints

Historically, there’s been a misdirected emphasis on resolving oppositional forces through dialectical synthesis (Hegel, *Encyclopaedia of the Philosophical Sciences*, 1817). This has led to solutions that are either too narrowly specific — like classification tasks — or too broadly generalized — as in clustering and latent variable models.

This dual modality is evident in the **hidden layers** of artificial neural networks, where outputs are confined to either specific classifications or generalizable patterns.

---

## LLMs and the Limits of Symbolic Processing

**Large Language Models (LLMs)** embody aspects of this shift by generating language through deep learning. While they move beyond classification and regression toward contextual, generative understanding, they remain constrained by their architectures and logics highlighted by Gödel’s incompleteness theorems.

LLMs attempt to reconcile rule-based processing and generative modeling but often fall short of a transcendental synthesis — echoing Hegel’s critique of simplistic resolutions. Their hidden layers still oscillate between rigid classifications and generalized patterns.

Consequently, while LLMs edge closer to holistic cognition, they remain tethered to existing paradigms — requiring innovations in representational spaces to realize comprehensive, experiential intelligence (Cuskley, Woods, et al.).

---

## Logico-Phenomena: A New Foundation

This synthesis in theory could allow AI systems to transcend syntax and engage with **semantics**, setting a new foundation for machine understanding that integrates logical precision with experiential context.

The proposed methodology formalizes **“logico-phenomena”** — a synthetic framework uniting analytic logic with phenomenological experience, bridging symbolic reasoning and semantics.

Peeling back representation layers, this broadens our scope of possible knowledge representations in neural networks and their ability to understand signifier and signified.

---

## The Artificial Agent as a Nondeterministic Causal Engine

Reimagining AI understanding allows us to see the **artificial agent** as a **nondeterministic causal engine**, where “understanding” emerges within intricate representation spaces.

This paradigm shift — informed by nomadically evolving cartographies — paves the way to formalize the phenomenological dimensions of machine cognition while addressing epistemic assumptions for control and safety.

---

## Toward Ethical and Political Accountability

Such a framework lays a foundation for **AI safety systems** and **AI ethics research** to advance technologically while staying adaptable to diverse contexts, promoting ethical sensitivity.

By integrating **posthumanist principles**, we can redefine the boundaries of machine intelligence — examining its technical capabilities and its broader implications for ontology, agency, and political accountability in an era shaped by nonhuman entities.

---

# Works Cited

- Foucault, Michel. *Discipline and Punish: The Birth of the Prison*. Trans. Alan Sheridan, Vintage Books, 1995.
- Foucault, Michel. *The Order of Things: An Archaeology of the Human Sciences*. Vintage Books, 1970.
- Deleuze, Gilles. “Postscript on the Societies of Control.” *October*, vol. 59, 1992.
- Han, Byung-Chul. *Psychopolitics: Neoliberalism and New Technologies of Power*. Trans. Erik Butler, Verso, 2017.
- Deleuze, Gilles & Guattari, Félix. *What Is Philosophy?* Trans. Hugh Tomlinson & Graham Burchell, Columbia University Press, 1994.
- Deleuze, Gilles & Guattari, Félix. *A Thousand Plateaus: Capitalism and Schizophrenia*. Trans. Brian Massumi, University of Minnesota Press, 1987.
- Ferrando, Francesca. *Philosophical Posthumanism*. Bloomsbury Academic, 2019.
- Docherty, Thomas. *The Politics of Affirmation: On Affirmation and Becoming*. Bloomsbury Academic, 2019.
- Bryant, Levi. *Onto-Cartography: An Ontology of Machines and Media*. Edinburgh University Press, 2014.
- Harman, Graham. *The Quadruple Object*. Zero Books, 2011.
- Morton, Timothy. *Humankind: Solidarity with Nonhuman People*. Verso, 2017.
- Haraway, Donna J. “A Cyborg Manifesto.” *Simians, Cyborgs, and Women: The Reinvention of Nature*, Routledge, 1991.
- Derrida, Jacques. *Of Grammatology*. Trans. Gayatri Chakravorty Spivak, Johns Hopkins University Press, 1976.
- Kant, Immanuel. *Critique of Pure Reason*. Trans. Paul Guyer & Allen W. Wood, Cambridge University Press, 1998.
- Gödel, Kurt. *On Formally Undecidable Propositions of Principia Mathematica and Related Systems*. Trans. Martin Hirzel, 2000.
- Shapley, Lloyd S. “A Value for n-Person Games.” *Contributions to the Theory of Games*, vol. II, Princeton University Press, 1953.
- Goodfellow, Ian, et al. “Generative Adversarial Nets.” *Advances in Neural Information Processing Systems*, vol. 27, 2014.
- Sundararajan, Mukund, Ankur Taly & Qiqi Yan. “Axiomatic Attribution for Deep Networks.” *ICML*, vol. 70, 2017.
- Sala, Frederic, et al. “Representation Tradeoffs for Hyperbolic Embeddings.” *ICML*, vol. 80, 2018.
- Google AI. *Google AI Explainability Whitepaper*. Google Cloud, 2019.
- Searle, John R. “Minds, Brains, and Programs.” *Behavioral and Brain Sciences*, vol. 3, 1980.
- Cuskley, Christine, Rebecca Woods, Molly Flaherty. “The Limitations of Large Language Models.” *Open Mind*, vol. 8, 2024.
- Pearl, Judea & Mackenzie, Dana. *The Book of Why: The New Science of Cause and Effect*. Basic Books, 2018.
- Huang-Po. *On Transmission of Mind*. Trans. John Blofeld, Grove Press, 1959.
